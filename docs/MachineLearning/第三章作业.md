# ã€Šæœºå™¨å­¦ä¹ ã€‹ç¬¬ä¸‰ç« ä½œä¸š

## 3.1

ç­”ï¼šï¼ˆ1ï¼‰è¯¥æ¨¡å‹ä¸­$b$ä¸è¾“å…¥æ²¡æœ‰å…³ç³»æ—¶æˆ–æ¨¡å‹å‡½æ•°ä¸€å®šè¿‡åŸç‚¹æ—¶ï¼›ï¼ˆ2ï¼‰è¯¥æ¨¡å‹åªç”¨äºå·®åˆ†åˆ†ææ—¶ï¼Œå› ä¸ºå‡è®¾å–ä¸¤å®ä¾‹$\boldsymbol{x}_i$å’Œ$\boldsymbol{x}_j(i\neq j)$ï¼Œ$f(\boldsymbol{x}_i) - f(\boldsymbol{x}_j ) = \boldsymbol{w}^\text{T}(\boldsymbol{x}_i - \boldsymbol{x}_j)$æ˜¯ä¸$b$æ— å…³çš„ã€‚

## 3.3

### 1.å‡†å¤‡æ•°æ®

```python
import numpy as np
from sklearn.model_selection import train_test_split

data = np.array([[0.697, 0.460, 1],
        [0.774, 0.376, 1],
        [0.634, 0.264, 1],
        [0.608, 0.318, 1],
        [0.556, 0.215, 1],
        [0.403, 0.237, 1],
        [0.481, 0.149, 1],
        [0.437, 0.211, 1],
        [0.666, 0.091, 0],
        [0.243, 0.267, 0],
        [0.245, 0.057, 0],
        [0.343, 0.099, 0],
        [0.639, 0.161, 0],
        [0.657, 0.198, 0],
        [0.360, 0.370, 0],
        [0.593, 0.042, 0],
        [0.719, 0.103, 0]])  # è¥¿ç“œæ•°æ®é›†3.0alpha
X = data[:, 0:2]  # å±æ€§
y = data[:, -1]  # æ ‡ç­¾
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3) #éšæœºåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
```

### 2.å®šä¹‰æ¨¡å‹

```python
class LogisticRegression:
    def __int__(self):
        pass
    
    def fit(self, X_, y_):
        # æ•°æ®è°ƒæ•´ä¸ºx_barå’Œ\beta, ä¾¿äºæ“ä½œ
        n, m = X_.shape
        m += 1
        X = np.append(X_, np.ones(n).reshape((n, 1)), axis=1).T
        y = y_.copy()
        beta = np.random.random(size=(m, 1))
        # ç‰›é¡¿è¿­ä»£æ³•
        epoch = 20
        for i in range(epoch):
            mul = beta.T @ X
            p1 = np.exp(mul) / (1 + np.exp(mul))  # è®¡ç®—p1çš„å…¬å¼
            fd = -np.sum(X * (y - p1), axis=1)  # è®¡ç®—ç‰›é¡¿è¿­ä»£ä¸­çš„ä¸€é˜¶å¯¼æ•°
            sd = np.zeros((m, m))  # è®¡ç®—ç‰›é¡¿è¿­ä»£ä¸­çš„äºŒé˜¶å¯¼æ•°
            for i in range(n):
                sd += X[:, i:i+1] @ X[:, i:i+1].T * (p1[0, i] * (1 - p1[0, i]))
            beta = beta - (np.linalg.inv(sd) @ fd).reshape((m, 1))  # ä¸€æ¬¡è¿­ä»£
        # è®­ç»ƒç»“æœåˆ†æ
        ans = (beta.T @ X) > 1
        self.beta = beta
        print("è®­ç»ƒé›†å‡†ç¡®ç‡: ", 1 - np.sum(np.abs(ans - y)) / n)

    def predict(self, X_, y_):
        # æµ‹è¯•ç»“æœåˆ†æ
        n = X_.shape[0]
        X = np.append(X_, np.ones(n).reshape((n, 1)), axis=1).T
        y = y_.copy()
        ans = (self.beta.T @ X) > 1
        print("æµ‹è¯•é›†å‡†ç¡®ç‡: ", 1 - np.sum(np.abs(ans - y)) / n)

```

### 3.ä½¿ç”¨æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹

```python
model = LogisticRegression()
model.fit(X_train, y_train)
model.predict(X_test, y_test)
```

è®­ç»ƒé›†å‡†ç¡®ç‡:  0.7272727272727273
æµ‹è¯•é›†å‡†ç¡®ç‡:  0.8333333333333334

## 3.5

### 1.å‡†å¤‡æ•°æ®

åŒ3.3

### 2.å®šä¹‰æ¨¡å‹è®¡ç®—ğœ”

```python
class LDA:
    def __init__(self):
        pass
    
    def fit(self, X, y):
        X0 = X[y == 0]  # åç“œ
        X1 = X[y == 1]  # å¥½ç“œ
        mu0 = np.mean(X0, axis=0).reshape((-1, 1))  # åç“œå‡å€¼
        mu1 = np.mean(X1, axis=0).reshape((-1, 1))  # å¥½ç“œå‡å€¼
        cov0 = np.cov(X0, rowvar=False)  # åç“œåæ–¹å·®
        cov1 = np.cov(X1, rowvar=False)  # å¥½ç“œåæ–¹å·®
        S_w = np.mat(cov0 + cov1)  # S_w
        U,Sigma,V = np.linalg.svd(S_w,full_matrices=False)  # å¥‡å¼‚å€¼åˆ†è§£
        self.omega = V.T @ np.linalg.inv(np.diag(Sigma)) @ U.T @ (mu0 - mu1)  # /omega
        # è¾“å‡ºç»“æœ
        ans = self.omega.T @ X.T < 0
        acc = 1 - np.sum(np.abs(ans - y)) / y.shape[0]
        print("è®­ç»ƒé›†å‡†ç¡®ç‡:", acc)
    
    def predict(self, X, y):
        # è¾“å‡ºç»“æœ
        ans = self.omega.T @ X.T < 0
        acc = 1- np.sum(np.abs(ans - y)) / y.shape[0]
        print("æµ‹è¯•é›†å‡†ç¡®ç‡:", acc)

```

### 3.ä½¿ç”¨æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹

```python
model = LDA()
model.fit(X_train, y_train)
model.predict(X_test, y_test)
```

è®­ç»ƒé›†å‡†ç¡®ç‡: 0.9090909090909091
æµ‹è¯•é›†å‡†ç¡®ç‡: 0.6666666666666667

## 3.7

ç­”ï¼šç»™å‡ºæ±‰æ˜è·ç¦»æ„ä¹‰ä¸‹ç†è®ºæœ€ä¼˜çš„ECOCäºŒå…ƒç ï¼š

|       | $f_1$ | $f_2$ | $f_3$ | $f_4$ | $f_5$ | $f_6$ | $f_7$ | $f_8$ | $f_9$  |
| ----- | ----- | ----- | ----- | ---- | ---- | ------- | ---- | ---- | ---- |
| $C_1$ | +1 | -1 | -1 | -1 | +1 | +1 | +1 | +1 | -1 |
| $C_2$ | -1 | +1 | -1 | -1 | +1 | -1 | -1 | +1 | -1 |
| $C_3$ | -1 | -1 | +1 | -1 | -1 | +1 | -1 | +1 | -1 |
| $C_4$ | -1 | -1 | -1 | +1 | -1 | -1 | +1 | +1 | -1 |

è¯æ˜å¦‚ä¸‹ï¼š

æ³¨æ„åˆ°æ€§è´¨ï¼šè‹¥ä¸¤ä¸ªåˆ†ç±»å™¨$f_i$å’Œ$f_j(i \neq j)$å¯¹æ ·ä¾‹çš„åˆ†ç±»äº’ä¸ºåç [å¦‚$(-1,-1,1,1)$å’Œ$(1,1,-1,-1)$]ï¼Œç”±äºå¾ˆå¤šç®—æ³•å¯¹å¾…0-1åˆ†ç±»æ˜¯å¯¹ç§°çš„ï¼ˆå³å¦‚æœå°†0-1ç±»äº’æ¢ï¼Œæœ€ç»ˆè®­ç»ƒå‡ºçš„æ¨¡å‹æ˜¯ä¸€æ ·çš„ï¼‰ã€‚è¿™æ ·ä¸€å¯¹åˆ†ç±»å™¨å®é™…ä¸Šå¯ä»¥ç®€åŒ–ä¸ºä¸€ä¸ªåˆ†ç±»å™¨ï¼Œå› æ­¤å¯ä»¥è®¡ç®—å‡ºåœ¨ä¸å‡ºç°äº’ä¸ºåç çš„æƒ…å†µä¸‹ï¼Œæœ€ä¼˜çš„ECOCç¼–ç é•¿åº¦ä¸º
$$
\binom{4}{1} + \frac{\binom{4}{2}}{2}=7
$$
ç”±äºå¯ä»¥å‘ç¼–ç ä¸­åŠ å…¥å†—ä½™ï¼Œå³å¯ä»¥åœ¨æœ€çŸ­ç¼–ç é•¿åº¦çš„æƒ…å†µä¸‹åŠ å…¥äº’ä¸ºåç çš„ä¸€å¯¹åˆ†ç±»å™¨ï¼Œå› æ­¤åªè¦ä¿è¯ç¼–ç é•¿åº¦ä¸º$7+2n(nä¸ºè‡ªç„¶æ•°)$å³å¯ä¿è¯å¾—å‡ºçš„ECOCç¼–ç æ˜¯æœ€ä¼˜çš„ã€‚

ç»¼ä¸Šï¼Œç”±äº$9=7+2\times 1$ï¼ˆ$f_8$å’Œ$f_9$æ˜¯åŠ å…¥çš„å†—ä½™åˆ†ç±»å™¨ï¼‰ï¼Œå› æ­¤ä¸Šè¿°ç»™å‡ºçš„ECOCäºŒå…ƒç æ˜¯ç†è®ºæœ€ä¼˜çš„ã€‚

## 3.9

ç­”ï¼šå¯¹OvRã€MvM æ¥è¯´ï¼Œç”±äº**å¯¹æ¯ä¸ªç±»è¿›è¡Œäº†ç›¸åŒçš„å¤„ç†**ï¼Œå…¶æ‹†è§£å‡ºçš„äºŒåˆ†ç±»ä»»åŠ¡ä¸­ç±»åˆ«ä¸å¹³è¡¡çš„å½±å“ä¼šç›¸äº’æŠµæ¶ˆï¼Œå› æ­¤é€šå¸¸ä¸éœ€ä¸“é—¨å¤„ç†ã€‚
