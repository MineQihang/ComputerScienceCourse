Chapter 4 Pipelining *
nConcepts and Characteristics of Pipelining * 流水线相关概念与特点

nFive steps every instruction be executed in? Fill and Drain.* 流水的5个阶段；通过时间与排空时间

nStructural hazards, Data hazards and Control hazards * 结构冲突、数据冲突、控制冲突

nWhat is stall in pipeline? What happens when a instruction is stalled.

nThree Generic Data Hazards: RAW,WAR,WAW *

nHow to Avoid 3 kinds of Hazards? * 避免/解决冲突

nPerformance Issues in Pipelining. ** 性能：时空图

关于流水线的几个特点:


对于每个stage时长不一样的,先把最长的那个stage(对应图中的蓝色线段)连起来,然后在每段蓝色线左右补充前后的stage

 

流水线的相关概念和特点:
流水线:将一个重复的时序过程分解成为若干个子过程(称为段,段数也是流水线的深度)，而每个子过程都由专用功能部件实现。把多个处理过程在时间上错开，依次通过各功能段，这样不同子过程就能并行执行。流水线不会加速指令的执行时间而是改善整体的吞吐量.

流水线特点:

0--流水线定义

1--多条指令同时执行

2--每一个段只执行一条指令的一部分

3--指令沿着流水线流动一次的时间间隔就是一个机器周期(因此最慢的段决定了cycle大小）

流水线瓶颈：时间最长的段

流水线的五个阶段:
IF(取指令)->ID(指令译码/取寄存器[针对分支转移指令])->EX(执行/有效地址计算)->MEM(存储器访问load或store)->WB(写到寄存器,如load或者ALU的计算结果),以RISC为例,每条指令长度4字节,每条指令执行时间至少是5 cycles



流水线的通过时间: 从任务开始到稳定工作状态(段被填满)所需要的时间

流水线的排空时间:从稳定工作状态结束到最终任务结果所需要的时间



 

stall时发生了什么?
1--Instructions issued later than this instruction are stalled(在stall指令后的全都得一起stall)

2--Instructions issued earlier than this instruction must continue(在前的必须continue)

 

流水线的三个冲突:
1--结构冲突: 因硬件资源竞争引起的冲突


(使用Stall解决结构冲突)
(通过增加硬件解决结构冲突 比如指令cache和数据cache分离的方法(上图结构冲突由于两个指令同时需要访问cache引起,load读数据,I3取指令)
2--数据冲突: 指令在数据流中重叠执行时需要用到前面指令的结果产生的冲突


(使用Stall解决数据冲突)
(使用旁路技术解决数据冲突) [定向技术:使用流水线寄存器组直接向后面的指令传递结果]
定向技术检测冲突的方法是： 当硬件检测到前面某条指令的结果寄存器就是当前指令的源寄存器时，控制逻辑会将前面那条指令的结果直接从其产生的地方前递到当前指令所需的位置。定向技术的实际硬件结构如下所示 



注意：

load指令和其他ALU指令不同，在使用定向（解决load和其后指令的冲突）时仍有可能冲突（因为load必须得等到mem段才能得到真正的数据，其他的ALU指令可能在Ex阶段就能算出结果，load必须访存）,如下,这时候需要旁路+Stall 一起用



旁路技术检测冲突在load指令RAW中的应用：在当前指令的ID段检测数据相关，可以看出只需要把load指令的结果寄存器（lw的MEM段寄存器）与load指令后的几条指令（包含当前指令sub）的（ID段）源寄存器地址进行比较，如果在同一级（如lw与and）则可以用旁路或者在后面（如lw与or）则无需操作（因为前半周期写后半周期读），如果在前面（如lw与sub）则需要stall
如果在指令中观察，则Lw的下一条指令只能stall+forward，下二条指令可以forward，下三条指令无需操作（无冲突）如下图所示


做系统结构实验的时候找到一个trick：

一般在有定向技术的情况下找RAW冲突，只需关注两条连续的指令中第一条是LW的（类似上图第二个），这种只能stall，如果两条连续指令中第一条不是LW，则可以通过定向解决，比如：

ADD r1 r1 r3

SW r1 0(r2)

ADD写r1 SW读r1 但是ADD的EX结果可以直接传给SW的EX（如果定向机构检测到前一个ALU的计算结果写入的寄存器【对应r1】就是当前ALU的源寄存器，那么控制逻辑就选择定向的数据作为ALU的输入，而不采用从通用寄存器组读出的数据）

截图（以后补，用MIPS的模拟器）

上面举例的都是RAW,另外还有WAR和WAW冲突（但是在MIPS中也就是五段流水线里只会出现RAW）: 





 

 

 

3--控制冲突: 流水线遇到分支指令或者其他改变PC值的指令所遇到的冲突


有两个解决思路：1-更早得决定branch是否该被选中（MIPS在ID段zero test） 2-更早得计算好分支转移的地址（MIPS在ID段算转移PC）

（如上右图将分支地址计算放在了ID阶段，MIPS中的branch test都是通过检测register的值是否为0，因此把zero test也一起移动到ID段（如前所示，Id段可以读寄存器）这样一旦决定转移分支就不用等到10指令的MEm走完）这样只需一个stall（若跳转，36的IF需要等10的ID出结果），相比之前的三个stall(若跳转，36的IF需要等10的MEM出结果),减少了penalty，具体如下图所示。



 

减少分支延迟（控制冲突）的四种方法总结：

（2，3统称为分支预测，是一种静态预测，【下一章会有动态分支预测，这里静态是指预测操作是预先订好的，一定成功或者一定失败，动态则是可以根据之前的分支实际执行情况动态选择本次分支是成功还是失败】）：

stall一直到mem段出结果
假设分支一定not taken（也就是不跳转，接着执行下面一条指令），如果真实结果是跳转则squash（挤压，可以理解为指令作废，就是上面的idle）
假设分支一定 taken，同样需要一个stall等ID出转移地址结果，在五段流水线中，如果最后not taken，还需要转回到i+1，需要寄存器存i+1地址，相比方法2完全没有好处
延迟分支，使用编译器进行指令静态调度（调到延迟槽中）【下一章会有指令动态调度】，MIPS用的是只有一条指令的延迟槽，这种方法和2实际上几乎没区别的，只不过槽里那条指令不会被squash，也可以不是i+1（填充盐池槽的指令选择如下二图所示）


几种方法的共同特点：都属于静态方法，对分支的处理方式在程序执行过程中固定不变，要么总是预测成功，要么总是预测失败。 

延迟分支几种调度策略和优缺点：



注意：

对于分支预测，无论是静态方法还是动态方法都是硬件和软件共同作用的结果！静态是说预测是提前预定好的，动态可以自我调整

对于调度，静态是指通过编译器在编译阶段进行的调度，动态是指通过硬件在执行过程中进行的调度

三种冲突的解决方法总结：




流水线性能指标：


例题1：


加速比（一定大于1）：


效率：
 效率相当于每一段的加速比，所以可以用总的加速比除以段数





带有stall的流水线性能：
（比如：CPI，如果流水线无stall那么cpi一定是1，因为每个时钟周期流出一条指令）



例题2：
加速比除了用总时间比值也可以用平均时间（=时钟周期*平均CPI）的比值来计算

假设非流水线实现的时钟周期时间为1ns，ALU和分支指令需要4个时钟周期，访问存储器指令需5个时钟周期，

上述指令在程序中出现的相对频率分别是：40%、20%和40%。

在基本的流水线中，假设由于时钟扭曲和寄存器建立延迟等原因，流水线要在其时钟周期时间上附加0.2ns的额外开销。

现忽略任何其他延迟因素的影响，请问：相对于非流水实现而言，基本的流水线执行指令的加速比是多少？



 



 



 

 

Chapter 5 ILP - 1
nWhat is Instruction-Level Parallelism (ILP) and the 2 approaches to exploit ILP * 指令级并行，静态与动态

nWhat is Basic Block * 基本块

nData Dependence (True dependence), Name Dependence (Anti-dependence, Output dependence) , Control Dependencies * 相关（与冲突的关系）

nUnrolled Loop and Minimizes Stalls * 循环展开

nDynamic Branch Prediction * 动态分支预测

qBranch History Table, Correlated Branch Prediction, Tournament Predictors，Branch Target Buffers 分支目标缓冲 *
什么是ILP？提高ILP的两种方法？
当指令之间不存在相关，他们在流水线中可以重叠起来并行执行，这种潜在的并行性称为指令级并行。

重叠执行指令以提高性能，两种方法：动态方法（改变硬件）软件方法（编译器调度）



什么是BB？

除入口和出口外没有其他分支（branch）的线性指令序列，BB内部的指令可能相互依赖（dependent），所以开发ILP更多是在BB之间。

比如循环级并行（loop-level parallelism）：

 for (i=1; i<=1000; i=i+1)
       x[i] = x[i] + s //（一个循环中的不同循环体并行执行）
其中每个循环体就是一个BB，共有1000个BB，ILP就是使得这1000个BB能并行计算，这个具体方法叫循环展开（unrolling loop）。

动态循环展开：动态分支预测（上一章的分支预测是一种静态的）
静态循环展开：编译器静态调度指令（后面还会介绍一种动态调度）


相关与冲突的关系
相关：两条指令之间存在某种依赖关系

冲突：在具体流水线中，由于相关的存在，使得指令流中下一条指令不能在指定的时钟周期开始执行

两者之间的关系：

相关性是程序的固有属性； 冲突是流水线的特性；

相关性的存在只预示着存在有冲突的可能性。

 

相关的分类
数据相关：后面的指令使用了前面指令的结果
一般都是能引起RAW冲突的相关



ILP的宗旨就是只在会影响结果的时候保留指令执行顺序，其他情况下尽可能改变顺序提高并行性



名相关：两条指令使用相同的寄存器名，而两者之间没有数据流动
包括反相关，一般都是能引起WAR冲突的



和输出相关，一般都是能引起WAW冲突的



反相关的解决方法：一般可以通过寄存器重命名，也可以编译器静态调度和硬件方法。

控制相关：由分支指令引起的相关
一般都是能引起控制冲突的相关



上图红字的意思是： 指令调度的时候不能跨越分支指令，也就是BNE之前的指令不能调度到BNe之后（一个特例是分支延迟中可以放在BNE的延迟槽，见后）

 

循环展开：




1 由上可见，BB内的指令调度能带来的ILP提升有限（虽然减少了总的cycles，但是其中真正想执行的指令只占3/7，剩下的四个都是为了分支转移）

2 同时右图中DADDUI之所以能插到L和ADD之间的stall中是因为他和L，ADD均不存在冲突！（可能有人会想他可能与L有WAR，实际上MIPS的五段流水线是不可能产生除了RAW之外的数据冲突的，原因见前，就算想冲突，L和DADDUI之间也得起码隔着两个拍才行（这样L的mem才能和DADDUI的ID冲突上））

3 此外还可以将BNE移动到S之前的一个stall中，此时S处于BNE的延迟槽中，不属于（S）跨越分支指令（BNE）的情况

由1 启发我们需要在BB之间进行调度，这种就是循环展开要做的：



重要！->总循环次数n=1000，假设每次循环展开成k=4个（如上左图所示，减少了循环控制和分支开销）然后进行寄存器重命名（避免冲突）和指令调度（如上右图所示，减少了空转周期提高效率）

实际上是先进行n mod k个loop，然后再展开成k个的大loop，对这个大loop再循环n/k次，n越大，就会有越多的时间花在循环展开后的大loop上

 

循环展开的优点和限制：
限制：

循环展开成大loop时，若k过大，指令cache的miss rate会增加
因为用到了重命名，寄存器可能不够
优点：

降低整体开销（通过二外的循环展开）
减少了branch的开销


动态分支预测：
动态相比静态的区别是使用从早期运行（earlier run）中收集的概要信息预测分支，并根据上次运行（last run）修改预测

branch history table
1-bit的BHT存在的问题：

最后一次预测错误不可避免，因为前面分支总是成功
第一次预测错误是源于上次程序的执行，因为上一次程序最后一次分支不成功（可通过2-bit解决,见下图）


Correlated Branch Prediction


2-bit的BHT存在的问题：

如果不止一个分支（branch）存在，前面的分支可能会影响后面的分支（称为相关分支，见下左图，只有b1 b2都是Not Taken，b3才能Taken）可以通过相关分支预测器解决（见下右图）


注意：2-bitBHT相当于（0,2）的相关分支预测器

例题：
一个（2,2）的分支预测器如下：求预测结果



上图中address是不同分支的地址，GBH记录了上一次run的时候两个相关分支的taken情况，根据add和GBH定位到对应的具体状态为01，则说明这次run的预测是Not Taken

Tournament Predictors


其中selector 长得类似（0,2）的predictor：





Branch Target Buffers
BTB的思想借鉴了指令cache，他是预先把已知的是branch的指令地址和预测地址都存起来，然后将当前PC值逐一与表中的指令地址比较，若相等则说明当前PC指向的指令是一条分支指令，此后系统不再抓取PC对应的指令而是fetch与之对应的predicted PC指向的指令，如下图所示：


————————————————
版权声明：本文为CSDN博主「ASR_THU」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/zongza/article/details/83780572